---
title: "Explore Bogdan's (2025) effect size data"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_download: true
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

# TODO

- in quantile regression, 5th percentile throws errors for peta2 so I've removed it for the moment.
- Re-running the data processing would add abs_B to the dataset and allow it to be included
- look into the impossible effect size - what proportion are extraction errors vs actually impossible values?
- Add random sampling and categorization of what sort of effects or comparisons give rise to what magnitdue of effect sizes? 
- Clarify source of each ES 
  - Save journal list to disk.
  - eg was peta2 explicitly reported or recalculated from F test? is it definitely peta2 and not eta2? were r values in text or also tables?
- Consider adding the cuijpers 2025 multi domain meta analysis data to answer the question of distribution of cohen's d in a specific area, i.e., RCTs of clinical interventions.

```{r, include=FALSE}

# set default chunk options
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

# disable scientific notation
options(scipen = 999) 

```

# Dependencies

```{r}

library(tidyverse)
library(scales)
library(janitor)
library(rlang)
library(patchwork)
library(ggridges)
library(knitr)
library(kableExtra)
library(quantreg)
library(ggstance)

```

# Load data

```{r}

data_effectsizes <- read_rds("../data/bogdan 2025/processed/data_effectsizes.rds")

data_effectsizes_possible <- data_effectsizes |>
  filter(possible == TRUE)

```

# Descriptives

## Impossible values

For bounded effect sizes

```{r}

data_effectsizes |>
  filter(type %in% c("peta2", "r", "abs_r", "rho", "abs_rho", "R2", "OR")) |>
  group_by(type) |>
  summarize(n = n(),
            percent_impossible = round_half_up(mean(!possible)*100, 3),
            n_impossible = sum(!possible)) |>
  arrange(desc(percent_impossible)) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

## Articles (by subfield)

```{r}

data_effectsizes_possible |>
  distinct(doi, .keep_all = TRUE) |>
  count() |>
  kable() |>
  kable_classic(full_width = FALSE)

data_effectsizes_possible |>
  distinct(doi, .keep_all = TRUE) |>
  count(subfield) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

## Journals

```{r}

# data_effectsizes_possible |>
#   distinct(doi, .keep_all = TRUE) |>
#   count(journal) |>
#   kable() |>
#   kable_classic(full_width = FALSE)

data_effectsizes_possible |>
  distinct(journal) |>
  count() |>
  kable() |>
  kable_classic(full_width = FALSE)

```

## Years

```{r}

data_effectsizes_possible |>
  distinct(year) |>
  arrange(desc(year)) |>
  slice(1, n()) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

## Frequency by effect size type

```{r}

data_effectsizes_possible |>
  count(type) |>
  arrange(desc(n)) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

## Extreme values 

8 largest Cohen's d values in the database, by unique DOI.

```{r}

data_effectsizes_possible |>
  filter(type %in% "d_native") |> # c("d_native", "abs_r", "R2")) |>
  group_by(type) |>
  arrange(desc(estimate)) |>
  slice_head(n = 14) |>
  select(doi, type, estimate) |>
  distinct(doi, .keep_all = TRUE) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

### Verification of extreme natively reported Cohen's d values

**Purvanova and Muros (2010)**

https://doi.org/10.1016/j.jvb.2010.04.006

“Q_D = 919.17” (p. 174)

Q statistic incorrectly extracted as d.

[no pubpeer comment needed]


**Atkinson et al., (2010)** 

Multiple Sexual Partnerships in a Sample of African-American Crack Smokers, https://doi.org/10.1007/s10461-007-9346-0

“Women had had significantly more total sex partners in the 30 days preceding their interview, on average, than men (14.2 vs. 7.9, t =-4.48, d = 690, P < .01).” (p. 51)

d was indeed reported, but does not reproduce from the t test:

SDs implied by differences in mean:

```{r}
# d = m_diff / sd_pooled; therefore sd_pooled = m_diff / d: 
sd_pooled <- (14.2 - 7.9) / 690
```

Implied $SD_{pooled}$ = `r sd_pooled`. This would require that almost all of the 497 males and 195 female in the sample each reported the same number of sexual partners, within each group.

Recalculated d from t value and df:

```{r}
effectsize::t_to_d(t = 4.48, 
                   df_error = 497 + 195 - 2, 
                   paired = FALSE, 
                   ci = 0.95, 
                   alternative = "two.sided")
```

Given that recalculated df from the Ns (497 + 195 - 2) = 609 matches the reported d, I suspect that the t-test's df has been mislabeled as the effect size.

https://pubpeer.com/publications/DDDBEA2AB1381B343EF23E2028F75B#1


**Eddington et al. (2014)**

https://doi.org/10.1177/1073191113517929

“Mardia’s test (Mardia, 1970) indicated significant departures from multivariate kurtosis (b2,d = 535.25, p < .001)” (p. 7)

Other test statistic incorrectly extracted as d.

[no pubpeer comment needed]


**Hoyo et al. (2019)**

https://doi.org/10.3389/fpsyg.2019.02293	

on the "A new version of the Dots spatial conflict task" used to measure "Executive Function" in children, “Participants took more time to respond to incongruent than congruent trials (d = 132.44, p < 0.001), and in the mixed block compared to the simple blocks (d = 339.45, p < 0.001).” (p. 8)

d was indeed reported, but does not seem to reproduce from the reported Ms and SDs (.xlsx in zotero); very roughly recalculated d for the simple vs mixed comparison d = 1.4

https://pubpeer.com/publications/A983972167F472FFCC0AFAEE921216#


**Firth et al. (2017)** 

[paraphrasing] "Reductions in general symptoms after a 10 week exercise program in psychiatric inpatients": Cohen's d = 204.

https://doi.org/10.1016/j.mhpa.2017.04.004

This is likely to be simply a typo: adding a decimal place to make the effect size d = .204 would bring it in line with other effect sizes reported in the paragraph.

https://pubpeer.com/publications/24998D2B750BA7927040318CCBD6C9#


**Bogliotti & Isel (2021)**

[paraphrasing] "differences in reaction times between experimental conditions in a behavioral paradigm": d = 181 and 54.

https://doi.org/10.3389/fpsyg.2021.655168

SDs likely misreported as Cohen's ds.

https://pubpeer.com/publications/FEC504747ABE62EE2071B3EF4A2ED7#1


**van der Horst et al. (2014)**

[paraphrasing] "when children do the cooking they consume more calories than when parents do the cooking": “(d =146 kcal; 47%; P = .004)” (p. 22) 

http://dx.doi.org/10.1016/j.appet.2014.03.030

d seems to refer to delta, the difference in means between conditions, rather than Cohen's d - although this is not explicated anywhere.

[no pubpeer comment needed]


**Bennett et al. (2015)**

ANOVA applied to RT data: “Pairwise comparisons indicated that the mean response latency during the first block were significantly longer than those in the third block, d = 95.11, SE = 30.91, p = 0.02, and fourth block, d = 117.22, SE = 36.10, p = 0.01.” (p. 8)

https://doi.org/10.3389/fpsyg.2015.00520

d seems to refer to delta, the difference in mean RTs between conditions, rather than Cohen's d - although this is not explicated anywhere.

[no pubpeer comment needed]


# Percentiles

```{r}

data_percentiles_long <- data_effectsizes_possible |>
  filter(type %in% unique(type)) |>
  group_by(type) |>
  summarise(
    across(
      .cols = everything(),
      .fns = list, 
      .names = "{.col}_list"
    ), # just for clarity — we only care about estimate column
    .groups = "drop_last"
  ) |>
  select(type, estimate = estimate_list) |>
  unnest(estimate) |>
  group_by(type) |>
  summarise(
    percentile = c(1, 5, 10, 20, 25, 30, 40, 50, 60, 70, 75, 80, 90, 95, 99) / 100,
    value = map_dbl(percentile, ~ quantile(estimate, probs = .x, na.rm = TRUE)),
    .groups = "drop"
  ) |>
  mutate(percentile = percentile * 100) 

data_percentiles <- data_percentiles_long |>
  pivot_wider(names_from = type, values_from = value) |>
  select(percentile,
         d_native, 
         d_s, 
         d_z, 
         
         abs_r, 
         #r, 
         #rho, 
         #abs_rho, 
         #sqrtR2,
         
         peta2, 
         R2, 
         
         #OR, 
         abs_OR, 
         #logOR, 
         
         chi2, 
         
         B, 
         #abs_B,
         stdB,
         abs_stdB)
         #Wald

```

## Overall

```{r}

data_percentiles |>
  mutate_if(is.numeric, round_half_up, digits = 2) |>
  kable() |>
  kable_classic(full_width = FALSE)

# data_percentiles |>
#   pivot_longer(col = -percentile,
#                names_to = "estimator",
#                values_to = "estimate") |>
#   ggplot(aes(as.factor(percentile), estimate)) +
#   geom_bar(stat = "identity", width = 0.8) +
#   theme_linedraw() +
#   facet_wrap(~ estimator, scales = "free")
#
# data_percentiles |>
#   pivot_longer(col = -percentile,
#                names_to = "estimator",
#                values_to = "estimate") |>
#   mutate(estimator = fct_relevel(estimator, 
#                                  "d_native", "d_s", "d_z", 
#                                  "abs_r", "R2", "peta2", 
#                                  "abs_OR")) |>
#   filter(estimator %in% c("d_native", "d_s", "d_z", "abs_OR", "peta2", "abs_r", "R2")) |>
#   ggplot(aes(as.factor(percentile), estimate)) +
#   geom_bar(stat = "identity", width = 0.8) +
#   theme_linedraw() +
#   facet_wrap(~ estimator, scales = "free")

```

### Plot

```{r}

data_percentiles_for_plot <- data_percentiles_long |>
  filter(type %in% c("d_native", 
                     "d_s", 
                     "d_z", 
                     "abs_r",
                     "peta2", 
                     "R2", 
                     "abs_OR",
                     "abs_stdB",
                     "chi2")) |>
  mutate(type_lab = case_when(
    type == "d_native" ~ "\"Cohen's\"~'|'*italic(d)*'|'~'(reported)'",
    type == "d_s"      ~ "\"Cohen's\"~'|'*italic(d)[s]*'|'~'(from t-test)'",
    type == "d_z"      ~ "\"Cohen's\"~'|'*italic(d)[z]*'|'~'(from t-test)'",
    type == "abs_r"    ~ "\"Pearson's\"~'|'*italic(r)*'|'",
    type == "peta2"    ~ "eta[p]^2",
    type == "R2"       ~ "italic(R)^2",
    type == "abs_OR"   ~ "\"|Odds Ratio|\"",
    type == "abs_stdB" ~ "'|'*italic(beta)*'|'",
    type == "chi2"     ~ "chi^2",
    TRUE ~ type
  )) |>
  mutate(type_lab = fct_relevel(
    type_lab,
    "\"Cohen's\"~'|'*italic(d)*'|'~'(reported)'",
    "\"Cohen's\"~'|'*italic(d)[s]*'|'~'(from t-test)'",
    "\"Cohen's\"~'|'*italic(d)[z]*'|'~'(from t-test)'",
    "\"Pearson's\"~'|'*italic(r)*'|'",
    "eta[p]^2",
    "italic(R)^2",
    "\"|Odds Ratio|\"",
    "'|'*italic(beta)*'|'",
    "chi^2"
  )) |>
  drop_na() 

```

```{r fig.height=4, fig.width=6}

labs_map <- c(
  d_native = "\"Cohen's\"~group('|',italic(d),'|')~'(reported)'",
  d_s      = "\"Independent Cohen's\"~group('|',italic(d)[s],'|')~'(recalculated from t-test)'",
  d_z      = "\"Dependent Cohen's\"~group('|',italic(d)[z],'|')~'(recalculated from t-test)'"
)

label_map_parsed <- function(map) {
  force(map)
  function(x) parse(text = unname(map[x]))
}

data_percentiles_for_plot |>
  filter(percentile < 99) |>
  filter(str_detect(type, "d_")) |>
  mutate(type = fct_relevel(type, "d_z", "d_native", "d_s")) |>
  ggplot(aes(value, percentile, color = type)) +  
  geom_line() +
  geom_point() +
  scale_y_continuous(
    #breaks = c(1, seq(5, 95, 5), 99), 
    breaks = c(1, seq(5, 95, 5)), 
    name = "Percentile"
  ) +
  scale_x_continuous(
    breaks = scales::breaks_pretty(n = 8), 
    #limits = c(0, 1), 
    name = expression("Cohen's" ~ group("|", italic(d), "|"))
  ) +
  theme_linedraw() +
  theme(
    panel.grid.minor = element_blank(),
    strip.placement = "outside",
    strip.background = element_blank(),  # no fill or box
    strip.text = element_text(colour = "black"),
    legend.position = c(0.65, 0.3)
  ) +
  scale_colour_discrete(
    name = "Method",
    breaks = c("d_z", "d_native", "d_s"),  # desired legend order
    #breaks = names(labs_map),
    labels = label_map_parsed(labs_map)
  )

ggsave("plots/percentiles_bogdan_d.png", width = 6, height = 4, dpi = 600)

```

```{r fig.height=8, fig.width=12}

data_percentiles_for_plot |>
  filter(percentile < 99) |>
  filter(!str_detect(type, "d_")) |>
  ggplot(aes(value, percentile)) +  
  geom_line() +
  geom_point() +
  scale_y_continuous(
    #breaks = c(1, seq(5, 95, 5), 99), 
    breaks = c(1, seq(5, 95, 5)), 
    name = "Percentile"
  ) +
  scale_x_continuous(
    breaks = scales::breaks_pretty(n = 8), 
    #limits = c(0, 1), 
    name = "Effect size"
  ) +
  theme_linedraw() +
  theme(
    panel.grid.minor = element_blank(),
    strip.placement = "outside",
    strip.background = element_blank(),  # no fill or box
    strip.text = element_text(colour = "black")
    #legend.position = c(0.8, 0.4)
  ) +
  facet_wrap(~ type_lab, 
             scales = "free", 
             strip.position = "bottom",
             labeller = label_parsed)

ggsave("plots/percentiles_bogdan_others.png", width = 12, height = 8, dpi = 600)

```

## By subfield

```{r}

# data_percentiles_by_subfield <- 
#   data_effectsizes_possible |>
#   filter(type %in% unique(type)) |>
#   group_by(type, subfield) |>
#   summarise(
#     across(
#       .cols = everything(),
#       .fns = list, 
#       .names = "{.col}_list"
#     ), # just for clarity — we only care about estimate column
#     .groups = "drop_last"
#   ) |>
#   select(type, subfield, estimate = estimate_list) |>
#   unnest(estimate) |>
#   group_by(type, subfield) |>
#   summarise(
#     percentile = c(1, 5, 10, 25, 50, 75, 90, 95, 99) / 100,
#     value = map_dbl(percentile, ~ quantile(estimate, probs = .x, na.rm = TRUE)),
#     .groups = "drop"
#   ) |>
#   mutate(percentile = percentile * 100) |>
#   pivot_wider(names_from = type, values_from = value) |>
#   select(subfield, 
#          percentile,
#          d_native, 
#          d_s, 
#          d_z, 
#          
#          abs_r, 
#          #r, 
#          #rho, 
#          #abs_rho, 
#          #sqrtR2,
#          
#          peta2, 
#          R2, 
#          
#          #OR, 
#          abs_OR, 
#          #logOR, 
#          
#          chi2, 
#          
#          B, 
#          #abs_B,
#          stdB,
#          abs_stdB) |>
#          #Wald
#   arrange(subfield, percentile)
# 
# data_percentiles_by_subfield |>
#   mutate_if(is.numeric, round_half_up, digits = 2) |>
#   kable() |>
#   kable_classic(full_width = FALSE)

# data_percentiles_by_subfield |>
#   pivot_longer(col = -c(percentile, subfield),
#                names_to = "estimator",
#                values_to = "estimate") |>
#   ggplot(aes(as.factor(percentile), estimate)) +
#   geom_bar(stat = "identity", width = 0.8) +
#   theme_linedraw() +
#   facet_grid(subfield ~ estimator, scales = "free")

# data_percentiles_by_subfield |>
#   pivot_longer(col = -c(percentile, subfield),
#                names_to = "estimator",
#                values_to = "estimate") |>
#   mutate(estimator = fct_relevel(estimator,
#                                  "d_native", "d_s", "d_z",
#                                  "abs_r", "R2", "peta2",
#                                  "abs_OR")) |>
#   filter(estimator %in% c("d_native", "d_s", "d_z", "abs_OR", "peta2", "abs_r", "R2")) |>
#   ggplot(aes(as.factor(percentile), estimate)) +
#   geom_bar(stat = "identity", width = 0.8) +
#   theme_linedraw() +
#   facet_grid(estimator ~ subfield, scales = "free")
# 
# data_percentiles_by_subfield |>
#   pivot_longer(col = -c(percentile, subfield),
#                names_to = "estimator",
#                values_to = "estimate") |>
#   mutate(estimator = fct_relevel(estimator,
#                                  "d_native", "d_s", "d_z",
#                                  "abs_r", "R2", "peta2",
#                                  "abs_OR")) |>
#   filter(estimator %in% c("d_native", "d_s", "d_z", "abs_OR", "peta2", "abs_r", "R2")) |>
#   ggplot(aes(as.factor(percentile), estimate, fill = subfield)) +
#   geom_bar(stat = "identity", width = 0.8, position = position_dodge(width = .8), color = "black") +
#   theme_linedraw() +
#   facet_wrap( ~ estimator, scales = "free")

```

```{r}

data_percentiles_by_subfield <- 
  data_effectsizes_possible |>
  filter(type %in% unique(type)) |>
  group_by(type, subfield) |>
  summarise(
    across(
      .cols = everything(),
      .fns = list, 
      .names = "{.col}_list"
    ), # just for clarity — we only care about estimate column
    .groups = "drop_last"
  ) |>
  select(type, subfield, estimate = estimate_list) |>
  unnest(estimate) |>
  group_by(type, subfield) |>
  summarise(
    percentile = c(1, 5, 10, 25, 50, 75, 90, 95, 99) / 100,
    value = map_dbl(percentile, ~ quantile(estimate, probs = .x, na.rm = TRUE)),
    .groups = "drop"
  ) |>
  mutate(percentile = percentile * 100) |>
  pivot_wider(names_from = subfield, values_from = value) |>
  filter(type %in% c("d_native",
                     "d_s",
                     "d_z",
                     "abs_r",
                     "peta2",
                     "R2",
                     "abs_OR",
                     "chi2",
                     "B",
                     "stdB",
                     "abs_stdB")) |>
  mutate(type = fct_relevel(type, 
                            "d_native",
                            "d_s",
                            "d_z",
                            "abs_r",
                            "peta2",
                            "R2",
                            "abs_OR",
                            "chi2",
                            "B",
                            "stdB",
                            "abs_stdB")) |>
  arrange(type, percentile)

data_percentiles_by_subfield |>
  mutate_if(is.numeric, round_half_up, digits = 2) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

# Ridge plots by subfield

```{r}

library(ggridges)

data_effectsizes_possible |>
  count(type)

data_effectsizes_possible |>
  filter(type == "d_native") |>
  group_by(type) |>
  filter(estimate <= quantile(estimate, .99, na.rm = TRUE)) |>
  ggplot(aes(x = estimate, y = subfield, fill = subfield)) +
  geom_density_ridges(alpha = 1) +
  theme_linedraw() +
  scale_x_continuous(breaks = breaks_pretty(n = 8)) +
  labs(x = "Cohen's d native",
       y = "") +
  scale_fill_viridis_d() +
  theme(legend.position = "none")

data_effectsizes_possible |>
  filter(type == "d_s") |>
  group_by(type) |>
  filter(estimate <= quantile(estimate, .99, na.rm = TRUE)) |>
  ggplot(aes(x = estimate, y = subfield, fill = subfield)) +
  geom_density_ridges(alpha = 1) +
  theme_linedraw() +
  scale_x_continuous(breaks = breaks_pretty(n = 8)) +
  labs(x = "Cohen's d_s",
       y = "") +
  scale_fill_viridis_d() +
  theme(legend.position = "none")

data_effectsizes_possible |>
  filter(type == "d_z") |>
  group_by(type) |>
  filter(estimate <= quantile(estimate, .99, na.rm = TRUE)) |>
  ggplot(aes(x = estimate, y = subfield, fill = subfield)) +
  geom_density_ridges(alpha = 1) +
  theme_linedraw() +
  scale_x_continuous(breaks = breaks_pretty(n = 8)) +
  labs(x = "Cohen's d_s",
       y = "") +
  scale_fill_viridis_d() +
  theme(legend.position = "none")

```

# Plot distributions

IS THIS TRIMMING THINGS WEIRDLY? WHERE IS THE ABSOLUTE SCORING IN THE BELOW?

```{r}

plot_es <- function(data, x, trim_lower = 0, trim_upper = 1, binwidth = 0.1, xlab, title, subtitle) {
  data_subset <- data |>
    filter(type == x)
  
  # plot limits
  p1 <- quantile(data_subset$estimate, trim_lower, na.rm = TRUE)
  p99 <- quantile(data_subset$estimate, trim_upper, na.rm = TRUE)
  
  ggplot(data_subset, aes(x = estimate)) +
    geom_histogram(binwidth = binwidth, boundary = 0) +
    theme_linedraw() +
    scale_x_continuous(limits = c(p1, p99), breaks = scales::breaks_pretty(n = 10)) +
    scale_y_continuous(breaks = scales::breaks_pretty(n = 6)) +
    labs(title = title, 
         subtitle = subtitle, 
         x = xlab,
         y = "Count")
}

p_d_native <- 
  plot_es(data_effectsizes_possible, "d_native", trim_upper = 0.99,
          xlab = expression("Cohen's "*italic(d)),
          title = expression("Absolute Cohen's "*italic(d)),
          subtitle = "0–99th percentile range")

p_d_s <- 
  plot_es(data_effectsizes_possible, "d_s", trim_upper = 0.99,
          xlab = expression("Cohen's "*italic(d)[s]),
          title = expression("Absolute Cohen's "*italic(d)[s]*" estimated from "*italic(t)*"-test"),
          subtitle = "0–99th percentile range")

p_d_z <- 
  plot_es(data_effectsizes_possible, "d_z", trim_upper = 0.99,
          xlab = expression("Cohen's "*italic(d)[z]),
          title = expression("Absolute Cohen's "*italic(d)[z]*" estimated from "*italic(t)*"-test"),
          subtitle = "0–99th percentile range")

p_peta2 <- 
  plot_es(data_effectsizes_possible, "peta2", trim_lower = 0.01, trim_upper = 0.99, binwidth = 0.01,
          xlab = expression(italic(eta)[p]^2),
          title = expression(italic(eta)[p]^2*" estimated from "*italic(F)*"-test"),
          subtitle = "1–99th percentile range")

p_abs_r <- 
  plot_es(data_effectsizes_possible, "abs_r", binwidth = 0.1,
          xlab = expression("Pearson's "*italic(r)),
          title = expression("Absolute Pearson's "*italic(r)),
          subtitle = "0–100th percentile range") + 
  coord_cartesian(xlim = c(-1, 1))

# data_effectsizes_possible |>
#   mutate(r_out_of_bounds = case_when(r < -1 ~ TRUE,
#                                      r > 1 ~ TRUE,
#                                      TRUE ~ FALSE)) |>
#   summarize(percent_r_out_of_bounds = mean(r_out_of_bounds)*100)

p_abs_rho <- 
  plot_es(data_effectsizes_possible, "rho", binwidth = 0.1,
          xlab = expression(italic(rho)),
          title = expression("Absolute "*italic(rho)),
          subtitle = "0–100th percentile range") + 
  coord_cartesian(xlim = c(-1, 1))

p_sqrtR2 <- 
  plot_es(data_effectsizes_possible, "sqrtR2", binwidth = 0.1,
          xlab = expression("sqrt R"^2),
          title = expression("sqrt R"^2),
          subtitle = "0–100th percentile range") + 
  coord_cartesian(xlim = c(-1, 1))

p_R2 <- 
  plot_es(data_effectsizes_possible, "R2", binwidth = 0.1,
          xlab = expression("R"^2),
          title = expression("R"^2),
          subtitle = "0–100th percentile range") + 
  coord_cartesian(xlim = c(-1, 1))

# dat_es |>
#   mutate(R2_out_of_bounds = case_when(R2 < -1 ~ TRUE,
#                                       R2 > 1 ~ TRUE,
#                                       TRUE ~ FALSE)) |>
#   summarize(percent_R2_out_of_bounds = mean(R2_out_of_bounds)*100)

p_stdB <- 
  plot_es(data_effectsizes_possible, "stdB", trim_lower = 0.01, trim_upper = 0.95, binwidth = 0.01,
          xlab = expression(beta),
          title = expression(beta),
          subtitle = "1–95th percentile range")

p_B <- 
  plot_es(data_effectsizes_possible, "B", trim_lower = 0.01, trim_upper = 0.95, binwidth = 0.1,
          xlab = expression("B"),
          title = expression("B"),
          subtitle = "1–95th percentile range")

p_wald <- 
  plot_es(data_effectsizes_possible, "Wald", trim_lower = 0, trim_upper = 0.95, binwidth = 1,
          xlab = expression("Wald"),
          title = expression("Wald"),
          subtitle = "1–95th percentile range")

p_chi2 <- 
  plot_es(data_effectsizes_possible, "chi2", trim_lower = 0, trim_upper = 0.9, binwidth = 5,
          xlab = expression(chi^2),
          title = expression(chi^2),
          subtitle = "0–90th percentile range of positive values") + 
  coord_cartesian(xlim = c(0, NA))

p_OR <- 
  plot_es(data_effectsizes_possible, "OR", trim_lower = 0.01, trim_upper = 0.98,
          xlab = expression("OR"),
          title = expression("OR"),
          subtitle = "1–98th percentile range")

p_abs_OR <- 
  plot_es(data_effectsizes_possible, "abs_OR", trim_upper = 0.98,
          xlab = expression("Absolute OR"),
          title = expression("Absolute OR"),
          subtitle = "0–98th percentile range")

p_logOR <- 
  plot_es(data_effectsizes_possible, "logOR", trim_lower = 0.01, trim_upper = 0.99,
          xlab = expression("log-odds"),
          title = expression("log-odds"),
          subtitle = "1–99th percentile range")

# plot_es(data_effectsizes_possible, z, trim_lower = 0.01, trim_upper = 0.98,
#         xlab = expression("z-score"),
#         title = expression("z-score"),
#         subtitle = "1–98th percentile range") +
#   geom_vline(xintercept = 1.96, color = "pink", linetype = "dashed")
#
# plot_es(dat_p, p_val, trim_lower = 0, trim_upper = 1, binwidth = 0.001,
#         xlab = expression(italic(p)*" value"),
#         title = expression(italic(p)*" value"),
#         subtitle = "Between 0 and .1") +
#   coord_cartesian(xlim = c(0, 0.1))
# 
# plot_es(dat_p, p_implied, trim_lower = 0, trim_upper = 1, binwidth = 0.001,
#         xlab = expression("Implied "*italic(p)*" value"),
#         title = expression("Implied "*italic(p)*" value"),
#         subtitle = "Between 0 and .1") +
#   coord_cartesian(xlim = c(0, 0.1))

```

## Combined Cohen's d plots

```{r fig.height=10, fig.width=6}

p_d_native + coord_cartesian(xlim = c(0,8)) +
  p_d_s + coord_cartesian(xlim = c(0,8)) +
  p_d_z + coord_cartesian(xlim = c(0,8)) +
  plot_layout(ncol = 1)

```

## Individual plots

```{r}

p_abs_r

p_peta2 +
  geom_vline(xintercept = .01, linetype = "dashed", color = "blue") +
  geom_vline(xintercept = .06, linetype = "dashed", color = "blue") +
  geom_vline(xintercept = .14, linetype = "dashed", color = "blue")

p_R2

p_abs_OR

p_chi2

p_B
p_stdB

```

# Quantile regression

```{r fig.height=5, fig.width=9}

quantile_regression_and_plot <- function(data, es_type, label){
  dat_for_reg <- data |> 
    filter(type == es_type) |>
    mutate(estimate = round_half_up(estimate, 2)) |>
    count(subfield, estimate)
  
  # fit quantile regressions at multiple quantiles
  #fit_05 <- rq(estimate ~ 0 + subfield, tau = 0.05, weights = n, method = "fn", data = dat_for_reg)
  fit_10 <- rq(estimate ~ 0 + subfield, tau = 0.10, weights = n, method = "fn", data = dat_for_reg)
  fit_25 <- rq(estimate ~ 0 + subfield, tau = 0.25, weights = n, method = "fn", data = dat_for_reg)
  fit_50 <- rq(estimate ~ 0 + subfield, tau = 0.50, weights = n, method = "fn", data = dat_for_reg)
  fit_75 <- rq(estimate ~ 0 + subfield, tau = 0.75, weights = n, method = "fn", data = dat_for_reg)
  fit_90 <- rq(estimate ~ 0 + subfield, tau = 0.90, weights = n, method = "fn", data = dat_for_reg)
  fit_95 <- rq(estimate ~ 0 + subfield, tau = 0.95, weights = n, method = "fn", data = dat_for_reg)
  fit_99 <- rq(estimate ~ 0 + subfield, tau = 0.99, weights = n, method = "fn", data = dat_for_reg)
  
  # wrangle and plot
  res <- bind_rows(
    # summary(fit_05, se = "nid")$coefficients |>
    #   as.data.frame() |>
    #   rownames_to_column(var = "subfield") |>
    #   mutate(percentile = 5),
    summary(fit_10, se = "nid")$coefficients |>
      as.data.frame() |>
      rownames_to_column(var = "subfield") |>
      mutate(percentile = 10),
    summary(fit_25, se = "nid")$coefficients |>
      as.data.frame() |>
      rownames_to_column(var = "subfield") |>
      mutate(percentile = 25),
    summary(fit_50, se = "nid")$coefficients |>
      as.data.frame() |>
      rownames_to_column(var = "subfield") |>
      mutate(percentile = 50),
    summary(fit_75, se = "nid")$coefficients |>
      as.data.frame() |>
      rownames_to_column(var = "subfield") |>
      mutate(percentile = 75),
    summary(fit_90, se = "nid")$coefficients |>
      as.data.frame() |>
      rownames_to_column(var = "subfield") |>
      mutate(percentile = 90),
    summary(fit_95, se = "nid")$coefficients |>
      as.data.frame() |>
      rownames_to_column(var = "subfield") |>
      mutate(percentile = 95),
    summary(fit_99, se = "nid")$coefficients |>
      as.data.frame() |>
      rownames_to_column(var = "subfield") |>
      mutate(percentile = 99)
  ) |>
    mutate(subfield = str_remove(subfield, "subfield"),
           percentile = as.factor(percentile)) |>
    rename(estimate = Value,
           se = `Std. Error`) |>
    mutate(subfield = fct_relevel(subfield,
                                  "Social Psychology",
                                  "Applied Psychology", 	
                                  "Clinical Psychology",
                                  "Developmental and Educational Psychology",			
                                  "Experimental and Cognitive Psychology",			
                                  "General Psychology"))
  
  # ggplot(res, aes(estimate, subfield, color = percentile)) +
  #   geom_linerangeh(aes(xmin = estimate - se*1.96, xmax = estimate + se*1.96),
  #                   position = position_dodge(width = 0.75)) +
  #   geom_point(position = position_dodge(width = 0.75)) +
  #   theme_linedraw() +
  #   ylab("") +
  #   scale_x_continuous(name = label, breaks = scales::breaks_pretty(n = 8)) +
  #   guides(color = guide_legend(reverse = TRUE)) 
  
  plot <- res |>
    filter(percentile %in% c(10, 25, 50, 75, 90, 95)) |>
    ggplot(aes(estimate, percentile, color = subfield)) +
    geom_linerangeh(aes(xmin = estimate - se*1.96, xmax = estimate + se*1.96),
                    position = position_dodge(width = 0.75)) +
    geom_point(position = position_dodge(width = 0.75)) +
    theme_linedraw() +
    scale_x_continuous(name = label, breaks = scales::breaks_pretty(n = 8)) +
    ylab("Percentile") +
    guides(color = guide_legend(reverse = TRUE)) 
  
  return(list(res = res,
              plot = plot))
}

quantile_regression_and_plot(data_effectsizes_possible, "d_native", "Cohen's d")
quantile_regression_and_plot(data_effectsizes_possible, "d_s", "Cohen's ds from t-test")
quantile_regression_and_plot(data_effectsizes_possible, "d_z", "Cohen's dz from t-test")
quantile_regression_and_plot(data_effectsizes_possible, "abs_r", "Absolute r")
quantile_regression_and_plot(data_effectsizes_possible, "peta2", "peta2") # throws error, needs fixing 
quantile_regression_and_plot(data_effectsizes_possible, "R2", "R2")
quantile_regression_and_plot(data_effectsizes_possible, "abs_OR", "Absolute OR")
#quantile_regression_and_plot(data_effectsizes_possible, "chi2", "chi2")
#quantile_regression_and_plot(data_effectsizes_possible, "B", "B")
#quantile_regression_and_plot(data_effectsizes_possible, "stdB", "")
quantile_regression_and_plot(data_effectsizes_possible, "abs_stdB", "Absolute std. B") 

```

# Session info

```{r}

sessionInfo()

```


